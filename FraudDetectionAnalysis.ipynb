{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMNUKhnxDM1B6amtEspTDRJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iraj259/Machine-Learning/blob/main/FraudDetectionAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SgotO1yTUJGR"
      },
      "outputs": [],
      "source": [
        "# -----------------------------------------\n",
        "# 1) Import libraries\n",
        "# -----------------------------------------\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DoubleType\n",
        "from pyspark.sql.functions import col, when\n",
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import RandomForestClassifier, GBTClassifier, LogisticRegression\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
        "from pyspark.ml.classification import RandomForestClassificationModel"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------\n",
        "# 2) Initialize Spark session\n",
        "# -----------------------------------------\n",
        "spark = SparkSession.builder.appName(\"FraudDetection\").getOrCreate()"
      ],
      "metadata": {
        "id": "Q7ALf1QwUbG0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------\n",
        "# 3) Define schema\n",
        "# -----------------------------------------\n",
        "schema = StructType([\n",
        "    StructField(\"step\", IntegerType(), True),\n",
        "    StructField(\"type\", StringType(), True),\n",
        "    StructField(\"amount\", DoubleType(), True),\n",
        "    StructField(\"nameOrig\", StringType(), True),\n",
        "    StructField(\"oldbalanceOrg\", DoubleType(), True),\n",
        "    StructField(\"newbalanceOrig\", DoubleType(), True),\n",
        "    StructField(\"nameDest\", StringType(), True),\n",
        "    StructField(\"oldbalanceDest\", DoubleType(), True),\n",
        "    StructField(\"newbalanceDest\", DoubleType(), True),\n",
        "    StructField(\"isFraud\", IntegerType(), True),\n",
        "    StructField(\"isFlaggedFraud\", IntegerType(), True)\n",
        "])"
      ],
      "metadata": {
        "id": "_sEUqfQCUfRU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------\n",
        "# 4) Load dataset\n",
        "# -----------------------------------------\n",
        "df = spark.read.csv(\"fraudDetection.csv\", header=True, schema=schema)\n"
      ],
      "metadata": {
        "id": "KRpWEO2OUhfH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------\n",
        "# 5) Preprocessing\n",
        "# -----------------------------------------\n",
        "# >>> CHANGE: added handleInvalid='keep' to avoid errors on unseen categories\n",
        "indexer = StringIndexer(inputCol=\"type\", outputCol=\"type_index\", handleInvalid=\"keep\")\n",
        "encoder = OneHotEncoder(inputCols=[\"type_index\"], outputCols=[\"type_encoded\"], handleInvalid=\"keep\")\n",
        "\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=[\"step\",\"amount\",\"oldbalanceOrg\",\"newbalanceOrig\",\n",
        "               \"oldbalanceDest\",\"newbalanceDest\",\"type_encoded\"],\n",
        "    outputCol=\"features\", handleInvalid=\"keep\"   # >>> CHANGE\n",
        ")\n",
        "\n",
        "df = df.withColumnRenamed(\"isFraud\", \"label\")"
      ],
      "metadata": {
        "id": "zqPGtTebUoF9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------\n",
        "# 6) Handle class imbalance\n",
        "# -----------------------------------------\n",
        "fraud_df = df.filter(col(\"label\") == 1)\n",
        "nonfraud_df = df.filter(col(\"label\") == 0)\n",
        "\n",
        "# >>> CHANGE: used downsampling instead of oversampling\n",
        "fraud_count = fraud_df.count()\n",
        "nonfraud_sampled = nonfraud_df.sample(withReplacement=False,\n",
        "                                      fraction=fraud_count / nonfraud_df.count(),\n",
        "                                      seed=42)\n",
        "balanced_df = fraud_df.union(nonfraud_sampled)"
      ],
      "metadata": {
        "id": "18dUvXBMUq5u"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------\n",
        "# 7) Train/test split\n",
        "# -----------------------------------------\n",
        "train_df, test_df = balanced_df.randomSplit([0.7, 0.3], seed=42)"
      ],
      "metadata": {
        "id": "eJt4hzPXUvNg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------\n",
        "# 8) Define models\n",
        "# -----------------------------------------\n",
        "# >>> CHANGE: added seed=42 for reproducibility\n",
        "rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\", seed=42)\n",
        "gbt = GBTClassifier(featuresCol=\"features\", labelCol=\"label\", seed=42)\n",
        "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\", maxIter=10)\n",
        "\n",
        "pipelines = {\n",
        "    \"RandomForest\": Pipeline(stages=[indexer, encoder, assembler, rf]),\n",
        "    \"GBT\": Pipeline(stages=[indexer, encoder, assembler, gbt]),\n",
        "    \"LogisticRegression\": Pipeline(stages=[indexer, encoder, assembler, lr])\n",
        "}"
      ],
      "metadata": {
        "id": "yYJSr8OnUx01"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------\n",
        "# 9) Evaluators\n",
        "# -----------------------------------------\n",
        "evaluator_roc = BinaryClassificationEvaluator(labelCol=\"label\", metricName=\"areaUnderROC\")\n",
        "evaluator_pr = BinaryClassificationEvaluator(labelCol=\"label\", metricName=\"areaUnderPR\")\n",
        "\n",
        "metrics = {}"
      ],
      "metadata": {
        "id": "GGj3XubiU0IH"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------\n",
        "# 10) Train and evaluate\n",
        "# -----------------------------------------\n",
        "for name, pipeline in pipelines.items():\n",
        "    model = pipeline.fit(train_df)\n",
        "    preds = model.transform(test_df)\n",
        "\n",
        "    auc_roc = evaluator_roc.evaluate(preds)\n",
        "    auc_pr = evaluator_pr.evaluate(preds)\n",
        "\n",
        "    tp = preds.filter((col(\"label\") == 1) & (col(\"prediction\") == 1)).count()\n",
        "    tn = preds.filter((col(\"label\") == 0) & (col(\"prediction\") == 0)).count()\n",
        "    fp = preds.filter((col(\"label\") == 0) & (col(\"prediction\") == 1)).count()\n",
        "    fn = preds.filter((col(\"label\") == 1) & (col(\"prediction\") == 0)).count()\n",
        "\n",
        "    precision = tp / (tp + fp + 1e-8)\n",
        "    recall = tp / (tp + fn + 1e-8)\n",
        "    f1 = 2 * precision * recall / (precision + recall + 1e-8)\n",
        "\n",
        "    metrics[name] = {\n",
        "        \"AUC-ROC\": auc_roc,\n",
        "        \"AUC-PR\": auc_pr,\n",
        "        \"Precision\": precision,\n",
        "        \"Recall\": recall,\n",
        "        \"F1-score\": f1,\n",
        "        \"TP\": tp, \"TN\": tn, \"FP\": fp, \"FN\": fn\n",
        "    }\n"
      ],
      "metadata": {
        "id": "nYF3g43BU4pR"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # -----------------------------------------\n",
        "    # 11) Feature importances (RandomForest only)\n",
        "    # -----------------------------------------\n",
        "    for stage in model.stages:\n",
        "        if isinstance(stage, RandomForestClassificationModel):\n",
        "            print(f\"Top 10 feature importances for {name}:\")\n",
        "            importances = stage.featureImportances\n",
        "            for idx, imp in enumerate(importances.toArray()):\n",
        "                print(f\"  Feature {idx}: {imp}\")\n"
      ],
      "metadata": {
        "id": "Xh2TDz9_U88V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  # -----------------------------------------\n",
        "    # 12) Save model\n",
        "    # -----------------------------------------\n",
        "try:\n",
        "        model.write().overwrite().save(f\"{name}_fraud_model\")\n",
        "except Exception as e:  # >>> CHANGE: error handling\n",
        "        print(f\"Could not save {name} model: {e}\")"
      ],
      "metadata": {
        "id": "i552sfIzVNdU"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------\n",
        "# 13) Print metrics\n",
        "# -----------------------------------------\n",
        "for name, vals in metrics.items():\n",
        "    print(f\"\\nModel: {name}\")\n",
        "    for k, v in vals.items():\n",
        "        print(f\"  {k}: {v:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QA7hLKRNVPnj",
        "outputId": "fcafa3d4-cb7b-494b-a32c-41555e733e7b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model: RandomForest\n",
            "  AUC-ROC: 0.9944\n",
            "  AUC-PR: 0.9939\n",
            "  Precision: 0.9598\n",
            "  Recall: 0.9536\n",
            "  F1-score: 0.9567\n",
            "  TP: 1027.0000\n",
            "  TN: 1092.0000\n",
            "  FP: 43.0000\n",
            "  FN: 50.0000\n",
            "\n",
            "Model: GBT\n",
            "  AUC-ROC: 0.9980\n",
            "  AUC-PR: 0.9977\n",
            "  Precision: 0.9816\n",
            "  Recall: 0.9916\n",
            "  F1-score: 0.9866\n",
            "  TP: 1068.0000\n",
            "  TN: 1115.0000\n",
            "  FP: 20.0000\n",
            "  FN: 9.0000\n",
            "\n",
            "Model: LogisticRegression\n",
            "  AUC-ROC: 0.9501\n",
            "  AUC-PR: 0.9483\n",
            "  Precision: 0.8772\n",
            "  Recall: 0.8422\n",
            "  F1-score: 0.8593\n",
            "  TP: 907.0000\n",
            "  TN: 1008.0000\n",
            "  FP: 127.0000\n",
            "  FN: 170.0000\n"
          ]
        }
      ]
    }
  ]
}